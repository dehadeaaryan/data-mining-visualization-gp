{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team_name         object\n",
       "driver_nat        object\n",
       "circuitRef        object\n",
       "year             float64\n",
       "round            float64\n",
       "starting_pos     float64\n",
       "finishing_pos    float64\n",
       "laps             float64\n",
       "quali_mean       float64\n",
       "driver_age       float64\n",
       "driver_dnf         int64\n",
       "car_dnf            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../reference/f1_cleaned.csv')\n",
    "data = data.rename(columns={'driver_name' : 'team_name'})\n",
    "data.drop(['code'], axis=1, inplace=True)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#we are not using a random split here, training with pre 2024 data and trying to predict the races that occured in 2024\n",
    "\n",
    "train = data[data.year<2024].copy()\n",
    "test = data[data.year==2024].copy()\n",
    "\n",
    "#testing set\n",
    "y_test = test.pop('finishing_pos')\n",
    "x_test = test\n",
    "\n",
    "#training set\n",
    "y_train = train.pop('finishing_pos')\n",
    "x_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns: ['team_name', 'driver_nat', 'circuitRef', 'year', 'round', 'starting_pos', 'laps', 'quali_mean', 'driver_age', 'driver_dnf', 'car_dnf']\n",
      "Selected columns: ['team_name', 'driver_nat', 'circuitRef', 'year', 'round', 'starting_pos', 'laps', 'quali_mean', 'driver_age', 'driver_dnf', 'car_dnf']\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected columns:\", x_train.columns.tolist())\n",
    "print(\"Selected columns:\", x_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding vars and scaling data\n",
    "\n",
    "cat_feat = ['team_name',\n",
    "            'driver_nat', \n",
    "            'circuitRef']\n",
    "x_num_feat = ['year',\n",
    "              'starting_pos', \n",
    "              'laps', \n",
    "              'driver_dnf', \n",
    "              'car_dnf',\n",
    "              'round',\n",
    "              'quali_mean',\n",
    "              'driver_age']\n",
    "\n",
    "#scale y later if needed for a distance model\n",
    "\n",
    "ct = ColumnTransformer(transformers=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', drop='first'), cat_feat), #avoid dummy var trap with OHE\n",
    "    ('scx', StandardScaler(), x_num_feat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2; 0.6458855299950413\n",
      "Root Mean Squared Error: 3.425204804831232\n",
      "Ranked MAE: 2.44258872651357\n",
      "Ranked R²: 0.6666574579820879\n",
      "Ranked RSME: 3.3232275480497737\n",
      "Adjusted R²: 0.6558580235754601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyendo/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Basic LR model\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', ct),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2;', r2)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "\n",
    "# Add predictions and actuals back to `test`\n",
    "test['pred_lr'] = y_pred\n",
    "test['finishing_pos'] = y_test  # reattach actuals for ranking\n",
    "\n",
    "# Convert actual and predicted to ranks within each race\n",
    "test['actual_rank'] = test.groupby('circuitRef')['finishing_pos'].rank(method='min')\n",
    "test['lr_rank'] = test.groupby('circuitRef')['pred_lr'].rank(method='min')\n",
    "\n",
    "# Calculate MAE and R² on ranks\n",
    "mae = mean_absolute_error(test['actual_rank'], test['lr_rank'])\n",
    "r2 = r2_score(test['actual_rank'], test['lr_rank'])\n",
    "rsme = np.sqrt((mean_squared_error(test['actual_rank'], test['lr_rank'])))\n",
    "\n",
    "n = x_test.shape[0]  # number of samples\n",
    "p = x_test.shape[1]  # number of features\n",
    "\n",
    "print(\"Ranked MAE:\", mae)\n",
    "print(\"Ranked R²:\", r2)\n",
    "print(\"Ranked RSME:\", rsme)\n",
    "\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print('Adjusted R²:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 1) Build statsmodels design matrix\n",
    "X_be = pd.get_dummies(x_train.drop(columns=['year']), drop_first=True)\n",
    "X_be = sm.add_constant(X_be).astype(float)\n",
    "y_num = y_train.astype(float)\n",
    "\n",
    "x_test_be = pd.get_dummies(x_test.drop(columns=['year']), drop_first=True)\n",
    "x_test_be = sm.add_constant(x_test_be).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns: ['const', 'round', 'starting_pos', 'laps', 'quali_mean', 'driver_age', 'driver_dnf', 'car_dnf', 'team_name_Aston Martin', 'team_name_Caterham', 'team_name_Ferrari', 'team_name_Haas F1 Team', 'team_name_Manor Marussia', 'team_name_McLaren', 'team_name_Mercedes', 'team_name_RB F1 Team', 'team_name_Red Bull', 'team_name_Sauber', 'team_name_Williams', 'driver_nat_Australian', 'driver_nat_Belgian', 'driver_nat_Brazilian', 'driver_nat_British', 'driver_nat_Canadian', 'driver_nat_Chinese', 'driver_nat_Danish', 'driver_nat_Dutch', 'driver_nat_Finnish', 'driver_nat_French', 'driver_nat_German', 'driver_nat_Indonesian', 'driver_nat_Italian', 'driver_nat_Japanese', 'driver_nat_Mexican', 'driver_nat_Monegasque', 'driver_nat_New Zealander', 'driver_nat_Polish', 'driver_nat_Russian', 'driver_nat_Spanish', 'driver_nat_Swedish', 'driver_nat_Thai', 'driver_nat_Venezuelan', 'circuitRef_americas', 'circuitRef_bahrain', 'circuitRef_baku', 'circuitRef_catalunya', 'circuitRef_hockenheimring', 'circuitRef_hungaroring', 'circuitRef_imola', 'circuitRef_interlagos', 'circuitRef_istanbul', 'circuitRef_jeddah', 'circuitRef_losail', 'circuitRef_marina_bay', 'circuitRef_miami', 'circuitRef_monaco', 'circuitRef_monza', 'circuitRef_mugello', 'circuitRef_nurburgring', 'circuitRef_portimao', 'circuitRef_red_bull_ring', 'circuitRef_ricard', 'circuitRef_rodriguez', 'circuitRef_sepang', 'circuitRef_shanghai', 'circuitRef_silverstone', 'circuitRef_sochi', 'circuitRef_spa', 'circuitRef_suzuka', 'circuitRef_vegas', 'circuitRef_villeneuve', 'circuitRef_yas_marina', 'circuitRef_zandvoort']\n",
      "Selected columns: ['const', 'round', 'starting_pos', 'laps', 'quali_mean', 'driver_age', 'driver_dnf', 'car_dnf', 'pred_lr', 'finishing_pos', 'actual_rank', 'lr_rank', 'team_name_Aston Martin', 'team_name_Ferrari', 'team_name_Haas F1 Team', 'team_name_McLaren', 'team_name_Mercedes', 'team_name_RB F1 Team', 'team_name_Red Bull', 'team_name_Sauber', 'team_name_Williams', 'driver_nat_Argentinian ', 'driver_nat_Australian', 'driver_nat_British', 'driver_nat_Canadian', 'driver_nat_Chinese', 'driver_nat_Danish', 'driver_nat_Dutch', 'driver_nat_Finnish', 'driver_nat_French', 'driver_nat_German', 'driver_nat_Japanese', 'driver_nat_Mexican', 'driver_nat_Monegasque', 'driver_nat_New Zealander', 'driver_nat_Spanish', 'driver_nat_Thai', 'circuitRef_americas', 'circuitRef_bahrain', 'circuitRef_baku', 'circuitRef_catalunya', 'circuitRef_hungaroring', 'circuitRef_imola', 'circuitRef_interlagos', 'circuitRef_jeddah', 'circuitRef_losail', 'circuitRef_marina_bay', 'circuitRef_miami', 'circuitRef_monaco', 'circuitRef_monza', 'circuitRef_red_bull_ring', 'circuitRef_rodriguez', 'circuitRef_shanghai', 'circuitRef_silverstone', 'circuitRef_spa', 'circuitRef_suzuka', 'circuitRef_vegas', 'circuitRef_villeneuve', 'circuitRef_yas_marina', 'circuitRef_zandvoort']\n"
     ]
    }
   ],
   "source": [
    "selected_cols = X_be.columns.tolist()\n",
    "print(\"Selected columns:\", selected_cols)\n",
    "print(\"Selected columns:\", x_test_be.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: drop 'driver_age' (p=0.394)\n",
      "Step 2: drop 'round' (p=0.333)\n",
      "No more features with p > 0.05; stopping.\n",
      "Selected columns: ['const', 'starting_pos', 'laps', 'quali_mean', 'driver_dnf', 'car_dnf', 'team_name_Aston Martin', 'team_name_Caterham', 'team_name_Ferrari', 'team_name_Haas F1 Team', 'team_name_Manor Marussia', 'team_name_McLaren', 'team_name_Mercedes', 'team_name_RB F1 Team', 'team_name_Red Bull', 'team_name_Sauber', 'team_name_Williams', 'driver_nat_Australian', 'driver_nat_Belgian', 'driver_nat_Brazilian', 'driver_nat_British', 'driver_nat_Canadian', 'driver_nat_Chinese', 'driver_nat_Danish', 'driver_nat_Dutch', 'driver_nat_Finnish', 'driver_nat_French', 'driver_nat_German', 'driver_nat_Indonesian', 'driver_nat_Italian', 'driver_nat_Japanese', 'driver_nat_Mexican', 'driver_nat_Monegasque', 'driver_nat_New Zealander', 'driver_nat_Polish', 'driver_nat_Russian', 'driver_nat_Spanish', 'driver_nat_Swedish', 'driver_nat_Thai', 'driver_nat_Venezuelan', 'circuitRef_americas', 'circuitRef_bahrain', 'circuitRef_baku', 'circuitRef_catalunya', 'circuitRef_hockenheimring', 'circuitRef_hungaroring', 'circuitRef_imola', 'circuitRef_interlagos', 'circuitRef_istanbul', 'circuitRef_jeddah', 'circuitRef_losail', 'circuitRef_marina_bay', 'circuitRef_miami', 'circuitRef_monaco', 'circuitRef_monza', 'circuitRef_mugello', 'circuitRef_nurburgring', 'circuitRef_portimao', 'circuitRef_red_bull_ring', 'circuitRef_ricard', 'circuitRef_rodriguez', 'circuitRef_sepang', 'circuitRef_shanghai', 'circuitRef_silverstone', 'circuitRef_sochi', 'circuitRef_spa', 'circuitRef_suzuka', 'circuitRef_vegas', 'circuitRef_villeneuve', 'circuitRef_yas_marina', 'circuitRef_zandvoort']\n",
      "Selected columns: ['const', 'starting_pos', 'laps', 'quali_mean', 'driver_dnf', 'car_dnf', 'pred_lr', 'finishing_pos', 'actual_rank', 'lr_rank', 'team_name_Aston Martin', 'team_name_Ferrari', 'team_name_Haas F1 Team', 'team_name_McLaren', 'team_name_Mercedes', 'team_name_RB F1 Team', 'team_name_Red Bull', 'team_name_Sauber', 'team_name_Williams', 'driver_nat_Argentinian ', 'driver_nat_Australian', 'driver_nat_British', 'driver_nat_Canadian', 'driver_nat_Chinese', 'driver_nat_Danish', 'driver_nat_Dutch', 'driver_nat_Finnish', 'driver_nat_French', 'driver_nat_German', 'driver_nat_Japanese', 'driver_nat_Mexican', 'driver_nat_Monegasque', 'driver_nat_New Zealander', 'driver_nat_Spanish', 'driver_nat_Thai', 'circuitRef_americas', 'circuitRef_bahrain', 'circuitRef_baku', 'circuitRef_catalunya', 'circuitRef_hungaroring', 'circuitRef_imola', 'circuitRef_interlagos', 'circuitRef_jeddah', 'circuitRef_losail', 'circuitRef_marina_bay', 'circuitRef_miami', 'circuitRef_monaco', 'circuitRef_monza', 'circuitRef_red_bull_ring', 'circuitRef_rodriguez', 'circuitRef_shanghai', 'circuitRef_silverstone', 'circuitRef_spa', 'circuitRef_suzuka', 'circuitRef_vegas', 'circuitRef_villeneuve', 'circuitRef_yas_marina', 'circuitRef_zandvoort']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 1) Build statsmodels design matrix\n",
    "X_be = pd.get_dummies(x_train.drop(columns=['year']), drop_first=True)\n",
    "X_be = sm.add_constant(X_be).astype(float)\n",
    "y_num = y_train.astype(float)\n",
    "\n",
    "x_test_be = pd.get_dummies(x_test.drop(columns=['year']), drop_first=True)\n",
    "x_test_be = sm.add_constant(x_test_be).astype(float)\n",
    "\n",
    "# 2) Map each original feature to its columns\n",
    "feature_groups = {}\n",
    "for f in x_num_feat:\n",
    "    feature_groups[f] = [f]\n",
    "for f in cat_feat:\n",
    "    feature_groups[f] = [c for c in X_be.columns if c.startswith(f + '_')]\n",
    "\n",
    "# 3) Iteratively drop groups\n",
    "SL = 0.05\n",
    "X_curr = X_be.copy()\n",
    "x_test_be = x_test_be.copy()\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "    full_mod = sm.OLS(y_num, X_curr).fit()\n",
    "    pvals = {}\n",
    "    for feat, cols in feature_groups.items():\n",
    "        # skip already-removed\n",
    "        if any(c not in X_curr.columns for c in cols):\n",
    "            continue\n",
    "        X_red = X_curr.drop(columns=cols)\n",
    "        red_mod = sm.OLS(y_num, X_red).fit()\n",
    "        anova = sm.stats.anova_lm(red_mod, full_mod)\n",
    "        pvals[feat] = anova['Pr(>F)'][1]\n",
    "    worst_feat, worst_p = max(pvals.items(), key=lambda x: x[1])\n",
    "    if worst_p > SL:\n",
    "        # drop group and remove from dict\n",
    "        print(f\"Step {step}: drop {worst_feat!r} (p={worst_p:.3f})\")\n",
    "        X_curr = X_curr.drop(columns=feature_groups[worst_feat])\n",
    "\n",
    "        x_test_be = x_test_be.drop(columns=feature_groups[worst_feat])\n",
    "\n",
    "        del feature_groups[worst_feat]\n",
    "        step += 1\n",
    "    else:\n",
    "        print(\"No more features with p > 0.05; stopping.\")\n",
    "        break\n",
    "\n",
    "selected_cols = X_curr.columns.tolist()\n",
    "print(\"Selected columns:\", selected_cols)\n",
    "print(\"Selected columns:\", x_test_be.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- actual_rank\n- driver_nat_Argentinian \n- finishing_pos\n- lr_rank\n- pred_lr\nFeature names seen at fit time, yet now missing:\n- circuitRef_hockenheimring\n- circuitRef_istanbul\n- circuitRef_mugello\n- circuitRef_nurburgring\n- circuitRef_portimao\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m model1\u001b[38;5;241m.\u001b[39mfit(X_curr, y_train)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mpredict(x_test_be)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Evaluate on raw values\u001b[39;00m\n\u001b[1;32m     51\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:788\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    787\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[1;32m    791\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:297\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:276\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    274\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 276\u001b[0m     X \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    277\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[1;32m   2836\u001b[0m     _estimator,\n\u001b[1;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m   2844\u001b[0m ):\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \n\u001b[1;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2919\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[1;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- actual_rank\n- driver_nat_Argentinian \n- finishing_pos\n- lr_rank\n- pred_lr\nFeature names seen at fit time, yet now missing:\n- circuitRef_hockenheimring\n- circuitRef_istanbul\n- circuitRef_mugello\n- circuitRef_nurburgring\n- circuitRef_portimao\n- ...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df created to compare results \n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Team': test['team_name'],              \n",
    "    'Circut': test['circuitRef'],          \n",
    "    'Actual Pos': y_test,                         \n",
    "    'Predicted Pos': y_pred                       \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.copy()\n",
    "test['y_pred'] = y_pred\n",
    "test['y_true'] = y_test.values\n",
    "\n",
    "\n",
    "test['actual_rank'] = test.groupby('circuitRef')['y_true'].rank(method='min')\n",
    "test['predicted_rank'] = test.groupby('circuitRef')['y_pred'].rank(method='min')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='actual_rank', y='predicted_rank', hue='team_name', data=test)\n",
    "\n",
    "#regression line\n",
    "plt.plot([1, test['actual_rank'].max()], [1, test['actual_rank'].max()], 'r--', label='Perfect Prediction')\n",
    "\n",
    "plt.xlabel('Actual Race Rank')\n",
    "plt.ylabel('Predicted Race Rank')\n",
    "plt.title('Predicted vs Actual Rankings by Team')\n",
    "plt.legend(title='Team', prop={'size': 8}, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting vs final positions in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding team colors\n",
    "team_colors = {\n",
    "    'Red Bull': '#1E41FF',\n",
    "    'Mercedes': '#00D2BE',\n",
    "    'Ferrari': '#DC0000',\n",
    "    'McLaren': '#FF8700',\n",
    "    'Aston Martin': '#006F62',\n",
    "    'Alpine F1 Team': '#0090FF',\n",
    "    'Williams': '#005AFF',\n",
    "    'RB F1 Team': '#6692FF',\n",
    "    'Haas F1 Team': '#B6BABD',\n",
    "    'Sauber': '#52E252',\n",
    "    #fallback color\n",
    "    'Other': '#888888'\n",
    "}\n",
    "palette = {team: color for team, color in team_colors.items() if team in test['team_name'].unique()}\n",
    "\n",
    "#getting unique races\n",
    "races = test['circuitRef'].unique()\n",
    "n_races = len(races)\n",
    "\n",
    "cols = 3\n",
    "rows = math.ceil(n_races / cols)\n",
    "\n",
    "plt.figure(figsize=(6 * cols, 5 * rows))\n",
    "\n",
    "for idx, race in enumerate(races):\n",
    "    ax = plt.subplot(rows, cols, idx + 1)\n",
    "    \n",
    "    race_data = test[test['circuitRef'] == race]\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        x='actual_rank', \n",
    "        y='predicted_rank', \n",
    "        hue='team_name', \n",
    "        data=race_data, \n",
    "        ax=ax,\n",
    "        palette=palette,\n",
    "        legend=False\n",
    "    )\n",
    "    \n",
    "    #regression line\n",
    "    ax.plot([1, race_data['actual_rank'].max()], [1, race_data['actual_rank'].max()], 'r--')\n",
    "    \n",
    "    #scale\n",
    "    max_rank = int(max(race_data['actual_rank'].max(), race_data['predicted_rank'].max())) + 1\n",
    "    ax.set_xticks(range(1, max_rank + 1))\n",
    "    ax.set_yticks(range(1, max_rank + 1))\n",
    "    \n",
    "    ax.set_xlim(0.8, max_rank + 0.2)\n",
    "    ax.set_ylim(0.8, max_rank + 0.2)\n",
    "\n",
    "    ax.set_title(f'{race.capitalize()}')\n",
    "    ax.set_xlabel('Actual Rank')\n",
    "    ax.set_ylabel('Predicted Rank')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Race-by-Race: Actual vs Predicted Driver Rankings by Team', fontsize=16, y=1.02)\n",
    "plt.legend(title='Team', bbox_to_anchor=(1.05, 1), loc='upper left', prop={'size': 8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_to_points(pos):\n",
    "    points_map = {1: 25, 2: 18, 3: 15, 4: 12, 5: 10,\n",
    "                  6: 8, 7: 6, 8: 4, 9: 2, 10: 1}\n",
    "    return points_map.get(pos, 0)\n",
    "\n",
    "test['actual_points'] = test['actual_rank'].apply(position_to_points)\n",
    "test['predicted_points'] = test['predicted_rank'].apply(position_to_points)\n",
    "\n",
    "team_points = test.groupby(['team_name', 'circuitRef']).agg({\n",
    "    'actual_points': 'sum',\n",
    "    'predicted_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "season_totals = team_points.groupby('team_name').agg({\n",
    "    'actual_points': 'sum',\n",
    "    'predicted_points': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "#sorting by actual\n",
    "season_totals = season_totals.sort_values(by='actual_points', ascending=False)\n",
    "\n",
    "\n",
    "teams = season_totals['team_name']\n",
    "x = np.arange(len(teams))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(x - width/2, season_totals['actual_points'], width, label='Actual')\n",
    "ax.bar(x + width/2, season_totals['predicted_points'], width, label='Predicted')\n",
    "\n",
    "ax.set_ylabel('Total Points')\n",
    "ax.set_title('Constructor Championship: Actual vs Predicted Points')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(teams, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(season_totals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
